{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMON9cKkZUTLsCZvKG6AZr/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uzairname/Documents/blob/main/CNN_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import convolve"
      ],
      "metadata": {
        "id": "o1CRwLa4eQuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## convolving and cross correlation\n",
        "\n",
        "CNNs are supervised learning. Show the differences from an MLP, and motivation for images.\n",
        "\n",
        "### an explanation\n",
        "\n",
        "Start from a regular fully connected NN. Each input represents some feature.\n",
        "\n",
        "Nodes in the hidden layer is some nonlinear combination of all the neurons in the layer before. Ends up with a really complicated function mapping inputs to outputs.\n",
        "\n",
        "But For an image, there are some differences: \n",
        "1. There are too many inputs (n by n by 3 color channels) to compute a fully connected layer.\n",
        "2. shifting an object in an image a little completely changes the value of pixels, but we don't care about shifts or translations.\n",
        "\n",
        "Kernel operators and corr operation take advantage of this. (briefly explain convolve operator)\n"
      ],
      "metadata": {
        "id": "off7M4pZeRPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "following along:\n",
        "\n",
        "reference completed notebook.."
      ],
      "metadata": {
        "id": "P-c4x8FlFG6q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzwmc3SRFGPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-L1X-Cf37t1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NczFXUlld-A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHhXpufzdcat"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def corr2d(X, K):\n",
        "\n",
        "    h, w = K.shape\n",
        "    Y = jnp.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y = Y.at[i, j].set((X[i:i + h, j:j + w] * K).sum())\n",
        "\n",
        "\n",
        "    return Y\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "\n"
      ],
      "metadata": {
        "id": "-Wc-SQguZvan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_NN9GQVkcoEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(np.array(x_train[-1][0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "N1evbRsfcYv-",
        "outputId": "544c345f-a111-410f-9940-592e170a5dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa22d5eafa0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchshape import tensorshape\n",
        "\n",
        "shape = tensorshape(nn.Conv2d(1, 6, 3), [4, 1, 28, 28])\n",
        "shape = tensorshape(nn.MaxPool2d(2, 2), shape)\n",
        "shape = tensorshape(nn.Conv2d(6, 10, 5), shape)\n",
        "shape = tensorshape(nn.MaxPool2d(2, 2), shape)\n",
        "\n",
        "print(shape)"
      ],
      "metadata": {
        "id": "WXXkGmmEdj2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nW3geVnAonDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n"
      ],
      "metadata": {
        "id": "4C4Okzz4oqKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision.datasets import KMNIST\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train = KMNIST(root=\"data\", train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "test = KMNIST(root=\"data\", train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "all = KMNIST(root=\"data\", download=True, transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "batch_size = 64\n",
        "loader_train = torch.utils.data.DataLoader(train, batch_size=64)\n",
        "loader_test = torch.utils.data.DataLoader(test, batch_size=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "vzw9wpwBorww",
        "outputId": "b5691f16-5d72-4979-95f6-ec52c4382d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-861a9952e2b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'root'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch CNN"
      ],
      "metadata": {
        "id": "bUea6Pf-oswF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect import modulesbyfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "n_classes = 10\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=(5, 5)) # play around with number of channels in hidden layer. Why do we need so many channels?\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "  \n",
        "    self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "  \n",
        "    self.fc1 = nn.Linear(in_features=800, out_features=500)\n",
        "    self.relu3 = nn.ReLU()\n",
        "  \n",
        "    self.fc2 = nn.Linear(in_features=500, out_features=10)\n",
        "    self.logSoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(self.relu1(self.conv1(x)))\n",
        "    x = self.pool2(self.relu2(self.conv2(x)))\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.relu3(self.fc1(x))\n",
        "    result = self.logSoftmax(self.fc2(x))\n",
        "    return result\n",
        "\n",
        "\n",
        "model = CNN()\n",
        "\n"
      ],
      "metadata": {
        "id": "FHg0TatQdeM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train things\n",
        "\n",
        "\n",
        "lossfn = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "%timeit\n",
        "model.train()\n",
        "running_loss = 0\n",
        "for epoch in range(2):\n",
        "\n",
        "  for i, batch in enumerate(loader_train):\n",
        "\n",
        "    x, y = batch\n",
        "    x, y = (x.to(device), y.to(device))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(x)\n",
        "    loss = lossfn(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss\n",
        "\n",
        "    if (i%200 == 0):\n",
        "      print(i, running_loss/200)\n",
        "      running_loss = 0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3zU1aSwIYR-",
        "outputId": "88121879-ca6f-4449-9d53-275ec2798fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor(0.0115, grad_fn=<DivBackward0>)\n",
            "200 tensor(1.2412, grad_fn=<DivBackward0>)\n",
            "400 tensor(0.3931, grad_fn=<DivBackward0>)\n",
            "600 tensor(0.2453, grad_fn=<DivBackward0>)\n",
            "800 tensor(0.1951, grad_fn=<DivBackward0>)\n",
            "0 tensor(0.1158, grad_fn=<DivBackward0>)\n",
            "200 tensor(0.1488, grad_fn=<DivBackward0>)\n",
            "400 tensor(0.1245, grad_fn=<DivBackward0>)\n",
            "600 tensor(0.1002, grad_fn=<DivBackward0>)\n",
            "800 tensor(0.1004, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(loader_test)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in loader_test:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "print(f'{100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN0RYGnDnW32",
        "outputId": "0c9a3d32-37f8-41ab-f9fa-534185ba679f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-qWeA74o2Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lenet"
      ],
      "metadata": {
        "id": "5aPK_tLdo2ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyimagesearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgTUVYUW79k6",
        "outputId": "249e5a42-f55e-4686-c607-600760df438c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyimagesearch (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pyimagesearch\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyimagesearch.lenet import LeNet\n",
        "\n",
        "trainData = KMNIST(root=\"data\", train=True, download=True,\n",
        "\ttransform=ToTensor())\n",
        "testData = KMNIST(root=\"data\", train=False, download=True,\n",
        "\ttransform=ToTensor())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "rbC180IEo3lH",
        "outputId": "739d6391-bff6-43a8-f4de-495a062de0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-35a15e5a46cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyimagesearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyimagesearch'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataiter = iter(loader_test)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "outputs = net(images)\n",
        "\n",
        "plt.imshow(images[0][0])\n",
        "labels[0], outputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "X49bhn5HmJOR",
        "outputId": "a871b930-efac-442e-ffd4-13fcdb3d5597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2),\n",
              " tensor([-0.1035,  0.2049, -0.1048,  0.1518, -0.2468,  0.0553,  0.2121, -0.1158,\n",
              "         -0.1200, -0.0190], grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/competitions/imagenet-object-localization-challenge/data\n",
        "\n",
        "dataset\n",
        "https://www.image-net.org/challenges/LSVRC/2017/index.php#\n",
        "\n",
        "Google CNN\n",
        "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf\n",
        "\n",
        "\n",
        "https://towardsdatascience.com/topological-data-analysis-tda-b7f9b770c951\n",
        "\n",
        "\n",
        "Stanford\n",
        "https://www.youtube.com/watch?v=bNb2fEVKeEo&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=5"
      ],
      "metadata": {
        "id": "lstTMzO9elEl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IweVTBVAe2CL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}